# Hyper-parameter-tuning
You will learn how to do initialization, Regularization, Gradient Checking and final Optimization techniques like (RMSProp-Exponential Weighted Average- Adam Optimization)
